{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WOw8yMd1VlnD"},"source":["# Data Preprocessing Lesson"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NvUGC8QQV6bV"},"source":["## Importing the libraries"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Downloading and installing libraries to the OS file system\n","!pip3 install numpy\n","!pip3 install matplotlib\n","!pip3 install pandas"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"wfFEXZC0WS-V"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fhYaZ-ENV_c5"},"source":["## Importing the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset = pd.read_csv('Data.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset.head(7)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset.isnull()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset.isnull().any()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset.isnull().sum().sum()"]},{"cell_type":"markdown","metadata":{},"source":["## Taking care of missing data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip3 install -U scikit-learn"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset = pd.read_csv('Data.csv')\n","X = dataset.iloc[:,:-1].values\n","X[:, 1:3]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.impute import SimpleImputer\n","imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n","imputer.fit(X[:, 1:3])\n","X[:, 1:3] = imputer.transform(X[:, 1:3])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(X[:, 1:3])"]},{"cell_type":"markdown","metadata":{},"source":["## Introduction to Visualizing Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = plt.hist(dataset.Age)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = plt.figure(figsize=(12, 6))\n","age = fig.add_subplot(121)\n","salary = fig.add_subplot(122)\n","\n","age.hist(dataset.Age, bins=10)\n","age.set_xlabel('Age')\n","age.set_title(\"Histogram of Age\")\n","\n","salary.hist(dataset.Salary, bins=10)\n","salary.set_xlabel('Salary ($)')\n","salary.set_title(\"Histogram of Salary\")\n","\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Feature Scaling"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = plt.scatter(dataset.Age, dataset.Salary)\n","plt.xlabel('Age')\n","plt.ylabel('Salary')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.plot(dataset.Age)\n","plt.plot(dataset.Salary)\n","plt.xlabel('Record Index')\n","plt.ylabel('Original Scale of Both Age and Salary')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Standard Scaler"]},{"cell_type":"markdown","metadata":{},"source":["Reload the array from the dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = dataset.iloc[:, :-1].values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(X[:, 1].min())\n","print(X[:, 1].max())\n","print(X[:, 2].min())\n","print(X[:, 2].max())"]},{"cell_type":"markdown","metadata":{},"source":["Notice the NaN and the numbers, let's apply imputation then check the scale again "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n","X[:, 1:3] = imputer.fit_transform(X[:, 1:3])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from  sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","sc.fit(X[:, 1:3])\n","X[:, 1:3] = sc.transform(X[:, 1:3])\n","X[:, 1:3]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(X[:, 1].min())\n","print(X[:, 1].max())\n","print(X[:, 2].min())\n","print(X[:, 2].max())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Reload the data\n","dataset = pd.read_csv('Data.csv')\n","X = dataset.iloc[:, :-1].values\n","# Impute the data\n","imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n","X[:, 1:3] = imputer.fit_transform(X[:, 1:3])\n","# Scale the data using \"fit_transform\" instead of \"fit\" then \"transform\"\n","sc = StandardScaler()\n","X[:, 1:3] = sc.fit_transform(X[:, 1:3])\n","X[:, 1:3]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sc_df = pd.DataFrame(X[:, 1:3], columns =['Age', 'Salary'])\n","plt.plot(sc_df['Age'])\n","plt.plot(sc_df['Salary'])\n","plt.xlabel('Record Index')\n","plt.ylabel('StandardScaler Scale w/o outlier')"]},{"cell_type":"markdown","metadata":{},"source":["Standard scaler formula for each element in the targeted series/column:\n","\n","$x_{scaled} = \\frac{x_{i} - \\mu} {\\sigma}$, where:\n","- $x_{i}$ is a number in the targeted series\n","- $\\mu$ is the calculated mean of all elements in the targeted series/column\n","- $\\sigma$ is the calculated standard deviation of all elements in the target series/column\n","- $x_{scaled}$ is the newly calculated value of the standard scaler to replace the corresponding original value, i.e., $x_{i}$"]},{"cell_type":"markdown","metadata":{},"source":["### Standard Scaler without imputation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Reload the data\n","dataset = pd.read_csv('Data.csv')\n","X = dataset.iloc[:, :-1].values\n","# Scale the data using \"fit_transform\" instead of \"fit\" then \"transform\"\n","sc = StandardScaler()\n","sc.fit(X[:, 1:3])\n","X[:, 1:3] = sc.fit_transform(X[:, 1:3])\n","X[:, 1:3]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sc_df = pd.DataFrame(X[:, 1:3], columns =['Age', 'Salary'])\n","plt.plot(sc_df['Age'])\n","plt.plot(sc_df['Salary'])\n","plt.xlabel('Record Index')\n","plt.ylabel('StandardScaler Scale w/o outlier w/o imputation')"]},{"cell_type":"markdown","metadata":{},"source":["![Alt text](image.png)"]},{"cell_type":"markdown","metadata":{},"source":["### Standard Scaler with outliers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Reload the data\n","dataset = pd.read_csv('Data-outlier.csv')\n","X = dataset.iloc[:, :-1].values\n","# Impute the data\n","imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n","X[:, 1:3] = imputer.fit_transform(X[:, 1:3])\n","# Scale the data using \"fit_transform\" instead of \"fit\" then \"transform\"\n","sc = StandardScaler()\n","sc.fit(X[:, 1:3])\n","X[:, 1:3] = sc.fit_transform(X[:, 1:3])\n","X[:, 1:3]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(X[:, 1].min())\n","print(X[:, 1].max())\n","print(X[:, 2].min())\n","print(X[:, 2].max())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sc_df = pd.DataFrame(X[:, 1:3], columns =['Age', 'Salary'])\n","plt.plot(sc_df['Age'])\n","plt.plot(sc_df['Salary'])\n","plt.xlabel('Record Index')\n","plt.ylabel('StandardScaler Scale w/ outlier')"]},{"cell_type":"markdown","metadata":{},"source":["### MinMax Scaler"]},{"cell_type":"markdown","metadata":{},"source":["Reload the array from the dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset = pd.read_csv('Data.csv')\n","X = dataset.iloc[:, :-1].values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n","X[:, 1:3] = imputer.fit_transform(X[:, 1:3])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","mms = MinMaxScaler()\n","X[:, 1:3] = mms.fit_transform(X[:, 1:3])\n","X[:, 1:3]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(X[:, 1].min())\n","print(X[:, 1].max())\n","print(X[:, 2].min())\n","print(X[:, 2].max())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mms_df = pd.DataFrame(X[:, 1:3], columns =['Age', 'Salary'])\n","plt.plot(mms_df['Age'])\n","plt.plot(mms_df['Salary'])\n","plt.xlabel('Record Index')\n","plt.ylabel('RobustScaler Scale w/o outlier')"]},{"cell_type":"markdown","metadata":{},"source":["X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n","X_scaled = X_std * (max - min) + min"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X"]},{"cell_type":"markdown","metadata":{},"source":["MinMax scaler formula for each element in the targeted series/column:\n","\n","$x_{std} = \\frac{x_{i} - \\min_{X}} {\\max_{X} - \\min_{X}}$, where:\n","- $x_{i}$ is a number in the targeted series\n","- $\\min_{X}$ is the smallest number in the targeted series\n","- $\\max_{X}$ is the largest number in the targeted series\n","- $x_{std}$ is the newly calculated value of a scale from 0..1 to replace the corresponding original value, i.e., $x_{i}$ \n","\n","$x_{scaled} = x_{std} * (max - min) + min$, where:\n","- $max$ is the maximum value of the required range\n","- $min$ is the minimum value of the required range\n","- $x_{scaled}$ is the newly calculated value of the MinMax scaler to replace the corresponding original value, i.e., $x_{std}$"]},{"cell_type":"markdown","metadata":{},"source":["### MinMax Scaler with outliers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Reload the data\n","dataset = pd.read_csv('Data-outlier.csv')\n","X = dataset.iloc[:, :-1].values\n","# Impute the data\n","imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n","X[:, 1:3] = imputer.fit_transform(X[:, 1:3])\n","# Scale the data using \"fit_transform\" instead of \"fit\" then \"transform\"\n","mms = MinMaxScaler()\n","mms.fit(X[:, 1:3])\n","X[:, 1:3] = mms.fit_transform(X[:, 1:3])\n","X[:, 1:3]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mms_df = pd.DataFrame(X[:, 1:3], columns =['Age', 'Salary'])\n","plt.plot(mms_df['Age'])\n","plt.plot(mms_df['Salary'])\n","plt.xlabel('Record Index')\n","plt.ylabel('MinMaxScaler Scale w/ outlier')"]},{"cell_type":"markdown","metadata":{},"source":["### Robust Scaler"]},{"cell_type":"markdown","metadata":{},"source":["Reload the array from the dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset = pd.read_csv('Data.csv')\n","X = dataset.iloc[:, :-1].values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n","X[:, 1:3] = imputer.fit_transform(X[:, 1:3])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import RobustScaler\n","rs = RobustScaler()\n","X[:, 1:3] = rs.fit_transform(X[:, 1:3])\n","X[:, 1:3]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(X[:, 1].min())\n","print(X[:, 1].max())\n","print(X[:, 2].min())\n","print(X[:, 2].max())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rs_df = pd.DataFrame(X[:, 1:3], columns =['Age', 'Salary'])\n","plt.plot(rs_df['Age'])\n","plt.plot(rs_df['Salary'])\n","plt.xlabel('Record Index')\n","plt.ylabel('RobustScaler Scale w/o outlier')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X[:, 1:3] = rs.inverse_transform(X[:, 1:3])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(X[:, 1:3])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ori_df = pd.DataFrame(X[:, 1:3], columns =['Age', 'Salary'])\n","plt.plot(rs_df['Age'])\n","plt.plot(rs_df['Salary'])\n","plt.xlabel('Record Index')\n","plt.ylabel('RobustScaler Scale w/o outlier')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('One SD values for age and salary: ', rs.inverse_transform([[1.5,1.5]]))\n","print('The mean values for age and salary: ', rs.inverse_transform([[0,0]]))"]},{"cell_type":"markdown","metadata":{},"source":["Robust scaler formula for each element in the targeted series/column:\n","\n","$x_{scaled} = \\frac{x_{i} - \\widetilde{X}} {X_{75} - X_{25}}$, where:\n","- $x_{i}$ is a number in the targeted series\n","- $\\widetilde{X}$ is the calculated median of all elements in the targeted series/column, a.k.a. $X_{50}$\n","- $X_{75}$ is the calculated $75^{th}$ percentile of all elements in the target series/column\n","- $X_{25}$ is the calculated $25^{th}$ percentile of all elements in the target series/column\n","- $x_{scaled}$ is the newly calculated value of the robust scaler to replace the corresponding original value, i.e., $x_{i}$"]},{"cell_type":"markdown","metadata":{},"source":["### Robust Scaler with outliers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Reload the data\n","dataset = pd.read_csv('Data-outlier.csv')\n","X = dataset.iloc[:, :-1].values\n","# Impute the data\n","imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n","X[:, 1:3] = imputer.fit_transform(X[:, 1:3])\n","# Scale the data using \"fit_transform\" instead of \"fit\" then \"transform\"\n","rc = RobustScaler()\n","X[:, 1:3] = rc.fit_transform(X[:, 1:3])\n","X[:, 1:3]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rc_df = pd.DataFrame(X[:, 1:3], columns =['Age', 'Salary'])\n","plt.plot(rc_df['Age'])\n","plt.plot(rc_df['Salary'])\n","plt.xlabel('Record Index')\n","plt.ylabel('RobustScaler Scale w/ outlier')"]},{"cell_type":"markdown","metadata":{},"source":["## Encoding categorical data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset = pd.read_csv('Data.csv')"]},{"cell_type":"markdown","metadata":{},"source":["### Encoding via Label Encoder"]},{"cell_type":"markdown","metadata":{},"source":["#### Encoding categorical variable with two values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y = dataset.iloc[:, -1].values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","y = le.fit_transform(y)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(y)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# It is possible to write compact code BUT this will make no reference to the learnt model\n","print(LabelEncoder().fit_transform(y))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(X.shape)\n","print(y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('X shape is: ', X.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('y shape is: ', y.shape)\n","print('y shape after reshape is: ', y.reshape((10,1)).shape)\n","print('y shape after reshape is: ', np.reshape(y, (10,1)).shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = dataset.iloc[:, :-1].values"]},{"cell_type":"markdown","metadata":{},"source":["#### Encoding categorical variable with more than two values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = dataset.iloc[:, :-1].values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X[:,0] = le.fit_transform(X[:,0])\n","print('Encoded Countries:\\n', X[:,0])\n","print('Printed dataset without the last column:\\n', X)"]},{"cell_type":"markdown","metadata":{},"source":["### Encoding via One Hot Encoder"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","ct = ColumnTransformer(\n","                        transformers=[\n","                                        (\n","                                            'encoder', \n","                                            OneHotEncoder(), \n","                                            [0]\n","                                        )\n","                        ], \n","                        remainder='passthrough'\n","                    )\n","X = ct.fit_transform(X)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["type(ct.fit_transform(X))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(X)"]},{"cell_type":"markdown","metadata":{},"source":["#### The next operation makes it easy to present the final representation of the dataset putting the all columns together using numpy concatenate method"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\n","    np.concatenate(\n","        (X, np.reshape(y, (10,1))), \n","         axis=1\n","    )\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Splitting the dataset into a Training set and a Test set"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset = pd.read_csv('Data.csv')\n","X = dataset.iloc[:, :-1].values\n","y = dataset.iloc[:, -1].values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 878)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 9)\n","X_train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 878)\n","X_train"]},{"cell_type":"markdown","metadata":{},"source":["# Assignment 1\n","\n","Find a data set with the following criteria that is having:\n","- at least three numerical columns,\n","- missing numerical values,\n","- numerical values should have outliers\n","- at least two categorical columns\n","- missing categorical values\n","\n","Write a program (as a notebook file) to achieve the following:\n","1. Impute the values using Scikit learn with a strategy that could fit missing string values\n","2. Scale the numerical values with the three discussed different methods and be able to interpret the different results and reason about the best method for the chosen data\n","3. Encode the categorical values with the two discussed different methods"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOD2/gZgY69JdiiGJVNfu7s","collapsed_sections":[],"name":"data_preprocessing_template.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
